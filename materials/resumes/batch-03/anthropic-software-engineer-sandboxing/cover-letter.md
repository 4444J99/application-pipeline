To the Sandboxing and AI Research Engineering Teams at Anthropic,

I am writing to apply for the Software Engineer (Sandboxing) position. As an independent engineer who has spent the last five years building a production-grade infrastructure of 103 repositories across 8 GitHub organizations, I bring a unique "security-as-medium" perspective to isolated execution environments. My work is defined by a "Cathedral → Storefront" philosophy: maintaining a deep, recursive systemic architecture while ensuring high-signal, scannable entry points for the researchers—and AI agents—that interact with it.

Anthropic’s mission to build reliable and steerable AI systems requires a sandboxing infrastructure that is both impenetrable and invisible to the developers who use it. My candidacy is built on three core pillars: large-scale systems orchestration, a rigorous testing culture, and a deep obsession with developer-facing API design.

1. **Systems Orchestration and Isolation at Scale:** I currently manage 21,160 code files coordinated through automated governance, including a validated dependency graph with 43 edges and zero back-edge violations. This architecture is sustained by 128 GitHub Actions workflows built on 18 reusable templates. I understand the staff-level challenges of error propagation and edge-case handling in distributed environments because I have architected and owned a system that mirrors institutional complexity as a solo practitioner. My experience with isolated execution—including building multi-agent orchestration frameworks—is directly applicable to the challenges of secure code execution.

2. **Rigorous Testing and Correctness:** I believe that sandboxing is only as good as the trust it inspires. My current corpus includes 2,349+ automated tests across 94 active repositories, with 100% coverage of core configuration schemas. In my `recursive-engine` project, I maintain 1,254 tests reaching 85% coverage. This discipline ensures that the client libraries and underlying infrastructure I build for Anthropic will not just be performant, but reliable infrastructure that researchers can trust implicitly for high-stakes safety experiments.

3. **AI-Conductor Methodology and API Design:** I am a power user of agentic coding tools and have built multi-agent orchestration frameworks (like `agentic-titan`) and reliability layers for the Claude Agent SDK. I bring a deep intuition for how LLMs interact with external systems—specifically how client-side libraries can be designed to make sandboxed execution intuitive while minimizing model-induced errors. I have documented this methodology across 42 published essays (~142K words), exploring where technical systems succeed and where reliability gaps create friction for builders.

I thrive in high-intensity, "brave" environments where the goal is to bridge the gap between frontier capabilities and production-grade engineering rigor. I am eager to contribute to Anthropic’s Sandboxing team, building the secure foundations that will enable Claude to safely interact with the world.

Thank you for your time and consideration.

Sincerely,

Anthony James Padavano

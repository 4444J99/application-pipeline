The developer experience of an AI API is the product. The documentation, the SDK design, the error messages, the playground, the dashboard — these are what developers evaluate when they decide whether to build on a platform. I've spent five years building full-stack infrastructure with this DX-first conviction, and I'm applying to OpenAI's Developer Experience team because the stakes of getting AI developer experience right are higher than for any other API product in history.

The full-stack evidence: 21,160 code files across 8 GitHub organizations. TypeScript strict mode on every TypeScript project, Python with type hints and PEP 8 across the backend. The frontend work includes an Astro 5 portfolio site with p5.js generative canvas, D3.js data visualization, Pagefind search indexing, and a design system built on CSS custom properties — component-driven architecture with semantic design tokens. The backend work includes Python CLI pipeline tools, YAML state machines, API integration layers for multiple job board APIs (Greenhouse, Ashby) with structured HTTP clients, error handling, and response parsing. MCP server infrastructure providing structured capabilities to AI development tools. This is full-stack engineering with a DX orientation at every layer.

The API integration depth: this application was produced by a 14-script Python CLI system that integrates with external APIs, manages structured state, and coordinates multi-step workflows. I've built API clients that handle authentication, rate limiting, error recovery, and response validation — the same engineering patterns that underpin SDK design. The experience of building on top of APIs gives me direct intuition for what makes an API developer experience good: predictable behavior, helpful error messages, consistent patterns, and documentation that answers the question you actually have.

The AI tooling dimension: I'm a daily power user of AI coding tools and have documented that experience across 42 essays (~142K words). I've built multi-agent orchestration systems (agentic-titan, 1,095 tests) and maintain MCP server infrastructure. I understand the developer experience of AI APIs from the practitioner's side — where token limits create friction, where streaming responses need careful handling, where function calling patterns are intuitive and where they're confusing. This practitioner knowledge is directly valuable for a team building the developer experience of the world's most-used AI API.

The documentation discipline: 810,000+ words across the system, 100% CLAUDE.md coverage, structured documentation at every level from quickstart to architectural overview. Developer experience engineering includes documentation — not as a separate concern, but as a product surface.

The gap: I have not worked on a product engineering team shipping developer-facing features at OpenAI's scale. My systems have no external users. What I bring is full-stack engineering across the entire DX surface — frontend, backend, CLI, API integration, documentation — combined with deep practitioner experience as an AI API consumer.

Portfolio: https://4444j99.github.io/portfolio/
GitHub: https://github.com/4444j99
